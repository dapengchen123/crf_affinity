## The code for Group Consistent Similarity Learning via Deep CRFs for Person Re-Identification

The master branch is for pytorch 0.3.0

If you use the pyotrch 0.4, please checkout to the  pytorch_4.0

## We are recruiting Research Intern and Full-time Researcher in Sensetime

Our research focused on large-scale (city-level) person re-ID and Face recognition.
We have sufficient computational resources and experienced computer vision research and engineering team located in Shenzhen and HongKong. Members include but not limited to [Rui Zhao](https://scholar.google.com/citations?user=1c9oQNMAAAAJ&hl=en), [Kaipeng](https://scholar.google.com/citations?user=4OqZBmYAAAAJ&hl=en) and [me](https://scholar.google.com/citations?user=-Wpd7FcAAAAJ&hl=en), we also have  excellent interns from top AI labs in and out of China. The current goal of our team is to develop continual learning system that can handle billions of person or face images, and can continuously improve the recognition accuracy (The work is going well, but we need more experienced researchers or programers that can futher enhance our system together with us). Besides, we are also interested in developing new person Re-ID or face recognition algorithm that may have academic value. 

We NEED full-time researchers that can engage in developing our continue learning system. We also welcome research interns to together explore the boarder of person re-ID and face recognition.

For the candidates, we expect you are very strong in the one of the following three aspects. 

1) Strong research skills , for example Postgraduate with paper in CCF A-tier conferences or journals (CVPR, ICCV, TPAMI etc.) / or Bachelor with paper CCF B-tier conferences or journals is plus

2) Strong programming skills, for example winners at ACM or related competitions, e.g. ACM pre-gold ; NOI silver or above; Star of Baidu finalist; or high-impact open source projects on github is plus

3) Experience of winning top leaderboard in research competitions, eg, Kaggle 

If you are interested in, please contact chendapeng@sensetime.com or zhaorui@sensetime.com
